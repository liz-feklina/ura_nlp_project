## ura_nlp_project

#### Бунтякова, Мартынова, Копылова, Цегоева

Для получения результатов необходимо скачать входные данные (файлы train_), тестовые данные (в тетрадке открываются как "test_texts.txt") и запустить тетрадку nlp_project. Выходные данные будут находиться в файлах test_pred_aspects.txt и test_pred_cats.txt

______________________________
## Отчёт

Мы начали работу с запуска бейзлайна и просмотра “проблемных” мест для первого задания. Мы хотели понять, что лишнего выделялось, и наоборот не выделялось, хотя было в разметке. 
С помощью ручного отсмотра данных, мы придумали несколько методов для улучшения бейзлайна. Поскольку бейзлайн работает на выделении тех слов, которые уже были выделены в train, мы решили убрать из ключевых слов те, которые встречались слишком редко (оптимальным порогом в ходе экспериментов оказался 5), таким образом мы улучшили score в среднем на 0.1. Дальше мы проанализировали аспекты на их морфологическую принадлежность и убрали из выделяемых аспектов все аспекты длины 1, если они не были глаголами или существительными (морфопарсер - pymorphy). Таким образом, наш алгоритм перестал распознавать странные аспекты типа наречий, которые иногда присутствовали в золотом стандарте, но чаще их всё-таки не стоило выделять.


Baseline:

Full match precision: 0.48<br>
Full match recall: 0.7159663865546219<br>
Partial match ratio in pred: 0.6197183098591549<br>
Full category accuracy: 0.46422535211267607<br>
Partial category accuracy: 0.6033802816901408<br>
Mention sentiment accuracy: 0.6772300469483568<br>
Mention sentiment accuracy: 0.5720670391061452<br>
Overall sentiment accuracy: 0.523943661971831<br>

Исключение редких слов:

Full match precision: 0.6124176857949201<br>
Full match recall: 0.5398009950248757<br>
Partial match ratio in pred: 0.7497648165569144<br>
Full category accuracy: 0.6086547507055503<br>
Partial category accuracy: 0.7215428033866416<br>
Mention sentiment accuracy: 0.6559139784946236<br>
Mention sentiment accuracy: 0.5684931506849316<br>
Overall sentiment accuracy: 0.6112676056338028<br>

Исключение аспектов длины 1, если они не глаголы или существительные:

Full match precision: 0.6449704142011834<br>
Full match recall: 0.5165876777251185<br>
Partial match ratio in pred: 0.7938856015779092<br>
Full category accuracy: 0.636094674556213<br>
Partial category accuracy: 0.7613412228796844<br>
Mention sentiment accuracy: 0.6834862385321101<br>
Mention sentiment accuracy: 0.6291390728476821<br>
Overall sentiment accuracy: 0.6366197183098592<br>
<br>

Также мы пробовали применять машинное обучение (логистическая регрессия) для задач оценки тональности упоминания аспекта и оценки тональности всего отзыва по категориям. Улучшенного результата удалось достичь на последней задаче: accuracy score составил 0.76.

В работе мы также пробовали использовать W2V (идея заключалась в поиске слов, близких к тем, которые выделяются как аспекты в уже готовой работе, особенно в категории еды). 
Также мы пробовали применять BERT, но для хороших результатов не хватило данных. Несмотря на то, что с помощью него технически удалось побить бейзлайн, данный результат не имеет смысла. Связано это с тем, что все отзывы разметились как положительные при изначальной выборке с 78% положительных отзывов. 

